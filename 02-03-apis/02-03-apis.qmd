---
title: "Acquiring data via an API"
subtitle: "Data Acquisition and Distribution"
author: Dr Zak Varty
date: ""
editor: source
format:
  revealjs:
    theme: ../eds-slides-theme.scss #(default / dark / simple)
    logo: assets/EDS-logo.jpg
    bibliography: ../refs.bib
    footer: "Effective Data Science: Data - APIs - Zak Varty"
    menu: true
    slide-number: true
    show-slide-number: all # (all / print / speaker)
    self-contained: true # (set to true before publishing html to web)
    chalkboard: false # (conflicts with self-contained)
      #src: drawings.json
      #theme: whiteboard
      #read-only: true
      #buttons: false
    width: 1600 # default is 1050
    height: 900 # default is 850
    incremental: false
---

## Aquiring data via an API

<br>

::::{.columns}
:::{.column width="60%"}
- You will often have to gather data for yourself. 

- There must be an easier way than scraping webpages. 

- APIs to the rescue! 

- See also: [Introduction to APIs](https://zapier.com/learn/apis/) and [DIY web data](https://stat545.com/diy-web-data.html#interacting-with-an-api) 
:::
:::{.column width="5%"}
:::
:::{.column width="35%"}
![](images/apis-and-httr.png)
:::
::::

:::{.notes}
We’ve already established that you can’t always rely on tidy, tabular data to land on your desk.

Sometimes you are going to have to go out and gather data for yourself. We have already seen how to scrape information directly from the HTML source of a webpage. But surely there has to be an easer way. Thankfully, there often is!

In this chapter we will cover the basics of obtaining data via an API. This material draws together the Introduction to APIs book by Brian Cooksey and the DIY web data section of STAT545 at the University of British Columbia.
:::

## Why do I need to know about APIs? 

- APIs are a common method for sharing data within and between businesses. 

>  An API, or *application programming interface*, is a set of rules that allows different software applications to communicate with each other.

- Convenient way to access data programatically. Benefits include:
  - **Automation** Faster and less chance of human error;
  - **Standardisation** Replication and code your data retrieval.
  
:::{.notes}

> An API, or application programming interface, is a set of rules that allows different software applications to communicate with each other.

As a data scientist, you will often need to access data that is stored on remote servers or in cloud-based services. APIs provide a convenient way for data scientists to programmatically retrieve this data, without having to manually download data sets or and process them locally on their own computer.

This has multiple benefits including automation and standardisation of data sharing.

- **Automation:** It is much faster for a machine to process a data request than a human. Having a machine handling data requests also scales much better as either the number or the complexity of data requests grows. Additionally, there is a lower risk of introducing human error. For example, a human might accidentally share the wrong data, which can have serious legal repercussions. 

- **Standardisation:** Having a machine process data requests requires the format of these requests and the associated responses to be standardised. This allows data sharing and retrieval to become a reproducible and programmatic aspect of our work.
::: 

## What is an API? 

<br>

- _Etiquette_ = Rules for human communication 

- _Protocol_ = Rules for computer communication

<br>

APIs are a standard protocol for different programs to interact with one another.

This allows modular development of specialised tools and greater progress overall. 

:::{.notes}
So then, if APIs are so great, what exactly are they? 

In human-to-human communication, the set of rules governing acceptable behaviour is known as etiquette. Depending on when or where you live, social etiquette can be rather strict. The rules for computer-to-computer communication take this to a whole new level, because with machines there can be no room left for interpretation. 

The set of rules governing interactions between computers or programs is known as a __protocol__. 

APIs provide a standard protocol for different programs to interact with one another. This makes it easier for developers to build complex systems by leveraging the functionality of existing services and platforms. The benefits of working in a standardised and modular way apply equally well to sharing data as they do to writing code or organising files. 
::: 

## API Communication

There are two sides to communication and when machines communicate these are known as the _server_ and the _client_. 

::::{.columns}
:::{.column width="55%"}
- _Server_: A program or computer used to store data or run programs on behalf of another program or computer. 

- _Client_: Any program or computer that uses the server. 
:::
:::{.column width="5%"}
:::
:::{.column width="40%"}
![](images/server-schematic.png)
:::
::::

:::{.notes}
There are two sides to communication and when _machines_ communicate these are known as the __server__ and the __client__. 

Servers can seem intimidating, because unlike your laptop or mobile phone they don't have their own input and output devices; they have no keyboard, no monitor, and no a mouse. Despite this, servers are just regular computers that are designed to store data and run programs. Servers don't have their own input or output devices because they are intended to be used _remotely_, via another computer. There is no need for a screen or a mouse if the user is miles away. Nothing scary going on here!

People often find clients much less intimidating - they are simply any other computer or application that might contact the sever. 
:::


## HTTP 

An API is a set of rules for computer communication, but how do they "talk" to one another? _Hyper Text Transfer Protocol_ (HTTP), or it's secure sibling HTTPS.

::::{.columns}
:::{.column width="60%"}

<br>
`https://www.imperial.ac.uk`

<br>

Uses a _request-response_ model of communication
:::
:::{.column width="5%"}
:::
:::{.column width="35%"}
![](images/request-response.png)
:::
::::

:::{.notes}
This leads us one step further down the rabbit-hole. An API is a protocol that defines the rules of how applications communicate with one another. But how does this communication happen? 

HTTP (Hypertext Transfer Protocol) is the dominant mode communication on the World Wide Web. You can see the secure version of HTTP, HTTPS, at the start of most web addresses up at the top of your browser. For example: `https://www.imperial.ac.uk/mathematics`. 

HTTP is the foundation of data communication on the web and is used to transfer files (such as text, images, and videos) between web servers and clients. 

To understand HTTP communications, I find it helpful to imagine the client and the server as being a customer and a waiter at a restaurant. The client makes some request to the server, which then tries to comply before giving a response. The server might respond to confirm that the request was completed successfully. Alternatively, the server might respond with an error message, which is (hopefully) informative about why the request could not be completed. 

This request-response model is the basis for HTTP, the same communication model that is used by APIs.  
:::



## HTTP Requests 

An HTTP request consists of: 

::::{.columns}
:::{.column width="40%"}
![](images/http-request.png)
:::
:::{.column width="5%"}
:::
:::{.column width="55%"}
<br>

- Uniform Resource Locator (URL)  
- Method (type of action requested)
- Headers (meta-information)
- Body (data) 
:::
::::

:::{.notes}
Let's look in a little more detail at the structure of an HTTP request. It has four main parts:

A URL or Uniform resource locator is unique identifier for a thing on the internet. Colloquailly this is known as a web address and they can point toward any type of object: a webpage but it can also point to a file, like an image or document, or else to an application or other form of software. In this case the URL will be used for database access.

The method tells the sever the type of action that the client has requested, and we will see some example methods shortly. 

The request headers contain meta-information about the request, for example the type of device that it was made from. This is important for webpages so that you get the correct mobile or desktop version. 

Finally, the body of the request contains any data that the client wants to send to the server. This might be for when making a remote backup of your data, for example. 
:::

## HTTP Methods

The most common HTTP Methods are: 

- `GET`
- `POST`
- `PUT`
- `PATCH`
- `DELETE`

The `GET` request is all you need for data acquisition, but the others will be used if you set up your own API to share data with others. 

:::{.notes}
he action that the client wants to take is indicated by a set of well-defined methods or HTTP verbs. The most common HTTP verbs are `GET`, `POST`, `PUT`, `PATCH`, and `DELETE`.

The `GET` verb is used to retrieve a resource from the server, such as a web page or an image. The `POST` verb is used to send data to the server, such as when submitting a form or uploading a file. The `PUT` verb is used to replace a resource on the server with a new one, while the `PATCH` verb is used to update a resource on the server without replacing it entirely. Finally, the `DELETE` verb is used to delete a resource from the server.

In addition to these common HTTP verbs, there are also several less frequently used verbs. These are used for specialized purposes, such as requesting only the headers of a resource, or testing the connectivity between the client and the server.
:::

## HTTP Responses 

::::{.columns}
:::{.column width="45%"}
![](images/http-response.png)
:::
:::{.column width="5%"}
:::
:::{.column width="50%"}
- No URL
- No method
- Status Code

<br>

Example status codes: `200`, `404`, `503`.

Successful API access gives data in JSON or XML format.
:::
::::

:::{.notes}
When the server receives a request it will attempt to fulfil it and then send a response back to the client. 

A response has a similar structure to a request apart from: 

- responses __do not have__ a URL,
- responses __do not have__ a method,
- responses __have__ a status code. 

__Status Codes__ 

The status code is a 3 digit number, each of which has a specific meaning. Some common error codes that you might (already have) come across are: 

- 200: Success,
- 404: Page not found (all 400s are errors),
- 503: Page down.

In a data science context, a successful response will return the requested data within the data field. This will most likely be given in JSON or XML format. 
:::


## Authentication 

<br>

> _Authentication_ is a way to ensure that only authorized clients are able to access an API. 

- Including secrect information in each request 

- We consider two methods: _Basic Authentication_ and _API Keys_. 

:::{.notes}
Now that we know _how_ applications communicate, you might ask how we can control who has access to the API and what types of request they can make. This can be done by the server setting appropriate permissions for each client. But then how does the server verify that the client is really who is claims to be?

__Authentication__ is a way to ensure that only authorized clients are able to access an API. This is typically done by the server requiring each client to provide some secret information that uniquely identifies them, whenever they make requests to the API. This information allows the API server to validate the authenticity this user before it authorises the request.
:::

## Authentication: Basic Auth vs API Keys

::::{.columns}
:::{.column width="47.5%"}
### Basic Authentication 

- User name (and password)
- Enrypted in Headers
- 401 error if not matching
- Can't control permissions
:::
:::{.column width="5%"}
:::
:::{.column width="47.5%"}
### API Keys
- random character sequence provided by server
- 401 error if not matching
- Individualised permissions 
- API use tracking
:::
::::

`http://example.com?api_key=my_secret_key`

:::{.notes}
__Basic Authentication__

There are various ways to implement API authentication. 

Basic authentication involves each legitimate client having a username and password. An encrypted version of these is included in the `Authorization` header of the HTTP request. If the hear matches with the server's records then the request is processed. If not, then a special status code (401) is returned to the client. 

Basic authentication is dangerous because it does not put any restrictions on what a client can do once they are authorised. Additional, individualised restrictions can be added by using an alternative authentication scheme. 

__API Key Authentication__

An API key is long, random string of letters and numbers that is assigned to each authorised user. An API key is distinct from the user's password and keys are typically issued by the service that provides an API. Using keys rather than basic authentication allows the API provider to track and limit the usage of their API. 

For example, a provider may issue a unique API key to each developer or organization that wants to use the API. The provider can then limit access to certain data. They could also limit the number of requests that each key can make in a given time period or prevent access to certain administrative functions, like changing passwords or deleting accounts.

Unlike Basic Authentication, there is no standard way of a client sharing a key with the server. Depending on the API this might be in the `Authorization` field of the header, at the end of the URL (`http://example.com?api_key=my_secret_key`), or within the body of the data. 
:::

## API Wrappers 

We've learned a lot about how computers communicate - how do we put this into practice?

- Mostly use this new internet knowledge for debugging

- API Wrapper functions should be your go-to, if they exist

[rOpenSci](https://ropensci.org/) has a curated list of many wrappers for accessing scientific data using R.

:::{.notes}
We've learned a lot about how the internet works. Fortunately, a lot of the time we won't have to worry about all of that new information other than for debugging purposes. 

In the best case scenario, a very kind developer has written a "wrapper" function for the API. These wrappers are functions in R that will construct the HTTP request for you. If you are particularly lucky, the API wrapper will also format the response for you, converting it from XML or JSON back into an R object that is ready for immediate use.  

One place that you might find some interesting API wrappers is [rOpenSci](https://ropensci.org/). This is a website that has a curated list of many wrappers for accessing scientific data using R.
:::

## `{geonames}` Wrapper

The GeoNames geographical database covers all countries and contains over eleven million place names that are available for download free of charge. 

- Can access directly, but using the `{geonames}` is much easier. 

- Purpose: Illustrate getting started with a new API. 

:::{.notes}
In this video we will take one API wrapper from rOpenSci as an example. The aim here is to illustrate the important steps of getting started with a new API. 

We'll focus on the [GeoNames API](https://www.geonames.org/), which gives open access to a geographical database. To access this data, we will use wrapper functions provided by the `{geonames}` [package](https://docs.ropensci.org/geonames/). 
:::

## Set up

::::{.columns}
:::{.column width="60%"}
<br>

1. Install and load `{geonames}` from CRAN

```{r echo = TRUE}
#install.packages("geonames")
library(geonames)
```

<br>

2. Create a [user account](https://www.geonames.org/login) for the GeoNames API
:::
:::{.column width="40%"}
![](images/sign-up.png)
:::
::::

## Set up (continued)

::::{.columns}
:::{.column width="50%"}

<br>

3. Activate the account (see activation email)

<br>

:::
:::{.column width="50%"}
![](images/confirmation-email.png)
:::
::::

4. Enable the free web services for your GeoNames account by logging in at this [link](http://www.geonames.org/enablefreewebservice).

## Set up (final step)

5. Tell R your credentials for GeoNames. 

::: {.callout-warning}
We could use the following code to tell R our credentials, but we absolutely should not.

```{r, eval=FALSE, echo=TRUE}
options(geonamesUsername="example_username")
```
:::

_Never put credentials in your code or under version control._ 

Keep them secret. Keep them safe. 

:::{.notes}
We could use the following code to tell R our credentials, but we absolutely should not so.

This would save our username as an environment variable, which is the meta-data about your R session. Environment variables control lots of things, like how many decimal places to print by default. Storing API details here is good because if you have lots of API credentials, do don't want them cluttering up the working environment of your IDE. 

However, adding these environment variables directly from your script is a bad idea. This is because it requires you to hard code your API details into the script. If you share the script with others (internally, externally or publicly) we would be sharing our credentials too. Not good!
:::


## Storing API Credentials {.smaller}

**Solution:** Store your credentials in environment variables as part of your `.Rprofile`. 

<br>

1. Open your `.Rprofile` from within R.   
```{r eval = FALSE, echo = TRUE}
usethis::edit_r_profile()
```

2. Add your credentials to the `.Rprofile`, save and close.
```{r eval = FALSE, echo = TRUE}
# Add you credentials to the R profile - save and close
options(geonamesUsername="example_username")
```

3. Restart R and access your safely stored credentials.
```{r eval = FALSE, echo = TRUE}
# Restart R and access your safely stored credentials
getOption("geonamesUsername")
```

<br>


**Gotchas:** Does your `.Rprofile` end with a blank line? Did you remember to restart R? 

:::{.notes}
The solution to this problem is still to store your credentials as environment variables, so that they don't clutter your workspace, but to do so in a special R script that is run each time a new R session begins. 

This special R script is called `.Rprofile`. Because it has a dot at the front, it is a hidden file and won't display by default in your file explorer. The easiest way to access it is to open or create it from within an R session but using the `edit_r_profile()` function from the `{usethis}` package. 

You can add the previous code to your Rprofile. You should save these changes and restart R. Your API credentials can be accessed using the `getOption()` function. 

Since your Rprofile lives outside of any particular project, your credentials are kept secret and safe. However, this means that your work is no longer entirely self contained and reporoducible. Make sure you give clear instructions on how other people should save their credentials so that they can reproduce your work.
:::


## Using `{geonames}` 

GeoNames has a whole host of [different geo-datasets](http://www.geonames.org/export/ws-overview.html). 

_Example:_ Get geo-tagged wikipedia articles within 1km of Imperial College London. 

```{r, echo=TRUE}
imperial_coords <- list(lat = 51.49876, lon = -0.1749)
search_radius_km <- 1

imperial_neighbours <- geonames::GNfindNearbyWikipedia(
  lat = imperial_coords$lat,
  lng = imperial_coords$lon, 
  radius = search_radius_km,
  lang = "en",                # English language articles
  maxRows = 500               # maximum number of results to return 
)
```


:::{.notes}
GeoNames has a whole host of [different geo-datasets](http://www.geonames.org/export/ws-overview.html) that you can explore. 
As a first example, let's get all of the geo-tagged wikipedia articles that are within 1km of Imperial College London. 
:::

## What do we get back? {.smaller}

<br>

```{r, echo=TRUE}
str(imperial_neighbours)
```

:::{.notes}
Looking at the structure of `imperial_neighbours` we can see that it is a data frame with one row per geo-tagged Wikipedia article.
:::


## Sense Checking 

<br>

Is what we are getting back from the API sensible? 

<br>



```{r, echo = TRUE}
imperial_neighbours$title[1:5]
```

:::{.notes}
To confirm we have the correct location we can inspect the title of the first five neighbouring Wikipedia articles.

There's nothing too surprising here, mainly departments of the college and Exhibition Road, which runs along one side of the campus. These sorts of check are important - I initially forgot the minus in the longitude and was getting results in East London!
:::

## What if there is no wrapper? 

::::{.columns}
:::{.column width="60%"}
<br>

- No need to panic, can submit a `GET` request directly using `{httr}`

- Example: get Mean Girls information from [OMDb](http://www.omdbapi.com/), an open source version of [IMDb](https://www.imdb.com/). 

- Need to [get an API key](http://www.omdbapi.com/apikey.aspx), verify by email and add your API key to `.Rprofile`.
:::
:::{.column width="5%"}
:::
:::{.column width="35%"}
![](images/meangirls.jpg)
:::
::::


## OMBb - Set Up

1. [Get an API key](http://www.omdbapi.com/apikey.aspx), and verify it by clicking the email link.

2. Add this key to your  `.Rprofile`, pasting in your own API key.

```{r, eval=FALSE, echo=TRUE}
usethis::edit_r_profile()
options(OMDB_API_Key = "PASTE YOUR KEY HERE")
``` 

3. Restart R and safely access your API key from within your R session. 

```{r, echo=TRUE}
ombd_api_key <- getOption("OMDB_API_Key")
```

## OMBb Making a Request {.smaller}

URL structure of OMDb API:

```
http://www.omdbapi.com/?t=<TITLE>&y=<YEAR>&plot=<LENGTH>&r=<FORMAT>&apikey=<API_KEY>
```

<br>

Function to write request URLs:
```{r, echo=TRUE}

#' Compose search requests for the OMBD API
#'
#' @param title String defining title to search for. Words are separated by "+".
#' @param year String defining release year to search for.
#' @param plot String defining whether "short" or "full" plot is returned.
#' @param format String defining return format. One of "json" or "xml".
#' @param api_key String defining your OMDb API key.
#'
#' @return String giving a OMBD search request URL.
#'
#' @example omdb_url("mean+girls", "2004", "short", "json", getOption(OMBD_API_Key))
omdb_url <- function(title, year, plot, format, api_key) {
  glue::glue("http://www.omdbapi.com/?t={title}&y={year}&plot={plot}&r={format}&apikey={api_key}")
}
```

:::{.notes}
Using the documentation for the API, requests have URLs of the following form, where terms in angular brackets should be replaced by your own search terms and api key value.  

With a little bit of effort, we can write a function that composes this type of request URL for us. We will using the `{glue}` package to help us join strings together. 
:::

## Submitting a request

```{r, echo=TRUE}
mean_girls_request <- omdb_url(
  title = "mean+girls",
  year =  "2004",
  plot = "short",
  format =  "json",
  api_key =  getOption("OMDB_API_Key"))
```

<br>

Using`{httr}` to construct our request and store the response we get.

```{r, echo=TRUE}
response <- httr::GET(url = mean_girls_request)
httr::status_code(response)
```

Thankfully, it was a success!

:::{.notes}
We can use the function that we have just written to generate the URL that we will use to access the OMBb API. 

We submit our GET request using the {httr} package. The result of this function is whatever the OMBb server's response to our request. This is quite a complicated data object so we store it in a variable called `response` and then inspect it's status code to see if all has gone to plan. 

A status code of 200 indicates that our request was successful, excellent! If you get a 401 error code here, check that you have clicked the activation link for your API key. 
:::

## Extracting the Film Data 

By looking at the structure of the response we can easily extract what we want from this list. 

```{r, echo=TRUE}
str(httr::content(response))
```


:::{.notes}
The full structure of the response is quite complicated, but we can easily extract the requested data about the Mean Girls film by using the `content()` function. HereI've only printed the first few list elements.

There we have it, task complete!
:::


## Wrapping Up 

- Learned about how computers and programs communicate.


- API keys live in your `.Rprofile` not in your code.
  - (make sure this is not under version control!)

<br>

- Wrapper > API > Scraping 
  - Don't repeat yourself, or others 
  - Don't work harder than you have to - `{omdbapi}` exists.

:::{.notes}
Wrapping up then. In this video we've learned a bit more about how the internet works, the benefits of using an API to share data and how to request data from Open APIs.

When obtaining data from the internet it's vital that you keep your credentials safe, and that don't do more work than is needed. 

- Keep your API keys out of your code. Store them in your `.Rprofile` (and make sure this is not under version control!)

- Scraping is always a last resort. Is there an API already? 
- Writing your own code to access an API can be more painful than necessary. 
- Don't repeat other people, if a suitable wrapper exists then use it. 

Thank you very much for your attention, and I'll see you in the next video.
:::

