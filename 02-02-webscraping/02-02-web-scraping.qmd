---
title: "Web Scraping with `{rvest}`"
subtitle: "Data Aquisition and Distribution"
author: Dr Zak Varty
date: ""
editor: source
format:
  revealjs:
    theme: ../eds-slides-theme.scss #(default / dark / simple)
    logo: assets/EDS-logo.jpg
    bibliography: ../refs.bib
    footer: "Effective Data Science: Data - Web Scraping - Zak Varty"
    menu: true
    slide-number: true
    show-slide-number: all # (all / print / speaker)
    self-contained: true # (set to true before publishing html to web)
    chalkboard: false # (conflicts with self-contained)
      #src: drawings.json
      #theme: whiteboard
      #read-only: true
      #buttons: false
    width: 1600 # default is 1050
    height: 900 # default is 850
    incremental: false
---

## Aquiring Data by Web Scraping

The data you need will not always be delivered to you, sometimes you have to go out and get it for yourself. 

<br>

- *Web scraping* is one common way to obtain this data 

- *APIs* are another common way to both obtain and distribute data

<br>

This video we will focus of the former: extracting data from a HTML webpage. 

::: {.notes}
You can't always rely on tabular data to land on your desk, nicely formatted or otherwise. Sometimes you are going to have to go out and gather data for yourself.

I'm not suggesting you will need to do this manually, but you will likely need to get data from the internet that's been made publicly or privately available to you. 

This might be information from a webpage that you gather yourself, or data shared with you by a collaborator using an API. In this lecture we will cover the basics of both.
:::

# 1. What is a webpage? 

:::{.notes}
Before we can even hope to get data from a webpage, we first need to understand _what_ a webpage is.
:::

## What is a webpage?

Like with LaTeX, content and presentation are handled separately. With webpages, this separation is even more extreme. 

<br>

- *HyperText Markup Language* (HTML) files store content of a webpage. 
 
- *Cascading Style Sheet* (CSS) files describe how that content should be displayed.


:::{.notes}
Webpages are written in a similar way to LaTeX: the content and styling of webpages are handled separately and are coded using plain text files. 

In fact, websites go one step further than LaTeX. The content and styling of websites are written in different files and in different languages. HTML (HyperText Markup Language) is used to write the content and then CSS (Cascading Style Sheets) are used to control the appearance of that content when it's displayed to the user. 
:::

## A Basic HTML page - Code

<br>
<br>

```{.html}
<html>
<head>
  <title>Page title</title>
</head>
<body>
  <h1 id='first'>A level 1 heading</h1>
  <p>Hello World!</p>
  <p>Here is some plain text &amp; <b>some bold text.</b></p>
  <img src='myimg.png' width='100' height='100'>
</body>
``` 

:::{.notes}
A basic HTML page with no styling applied might look something like this.

Just like XML data files, HTML has a hierarchical structure. This structure is crafted using HTML elements.
:::

## A Basic HMTL Page - In Browser 

```{r}
#| out-height: "500"
knitr::include_graphics("images/example-html-screenshot.png")
```

[CSS Zen Garden](http://www.csszengarden.com/) - multiple CSS files formatting the same HTML.  

:::{.notes}
When viewed in a browser, this basic HTML script would look something like this.

HTML files contain only the content and structure of a webpage, so this looks incredibly basic. The formatting applied with CSS is what gives webpages their unique feel or brand identity.  

The CSS Zen Garden project is designed to highlight this by inviting people to get as creative as they can, applying the different style sheets to the same HTML content. 
:::

## A Basic HTML Page - Structure  

<br>
<br>

```{.html}
<html>
<head>
  <title>Page title</title>
</head>
<body>
  <h1 id='first'>A level 1 heading</h1>
  <p>Hello World!</p>
  <p>Here is some plain text &amp; <b>some bold text.</b></p>
  <img src='myimg.png' width='100' height='100'>
</body>
```

<br>

. . . 

- Escape characters: > is `&gt;`,  < is `&lt;`, & is `&amp;`, ...

:::{.notes}
Each HTML element is made up of of a start tag, optional attributes, an end tag. 

We can see each of these in the first level header on line six. The opening tag is the h1 enclosed in angular brackets (the less than and greater than signs). An additional attribute is given within the opening tag, `id='first'`. Finally, the forward slash h1 enclosed in angular brackets is the closing tag. 

Everything between the opening and closing tag are the contents of that element. There are also some special elements that consist of only a single tag and its optional attributes. An example of this is the `<img>` tag. 

(press to next slide)

Since `<` and `>` are used for start and end tags, you can’t write them directly in an HTML document. Instead, you have to use escape characters. This sounds fancy, but it's just an alternative way to write characters that serve some special function within a language. 

You can write greater than `&gt;` and less than as `&lt;`. You might notice that those escapes use an ampersand (&). This means that if you want a literal ampersand on your webpage, you have to escape too using `&amp;`.

There are a wide range of possible HTML tags and escapes. We'll cover the most common tags in this lecture and you don’t need to worry about escapes too much because `{rvest}` will automatically handle them for you.
:::

## Important HTML Elements 

- The `<html>` element must enclose every HTML page:
  - `<head>` element contains metadata,
  - `<body>` element contains content displayed in browser.

- Block elements: headers `<h1>`, ..., `<h6>`, paragraphs `<p>`, lists `<ol>` & `<ul>`.


- Inline elements: bold `<b>`, italic `<i>`, emphasis `<em>`, hyperlinks `<a>`. 


Resources: [MDN Web Docs](https://developer.mozilla.org/en-US/docs/Web/HTML) & [W3schools website](https://www.w3schools.com/html/default.asp).

:::{.notes}
In all, there are in excess of 100 HTML elements. The most important ones for you to know about are:

 - The `<html>` element, that must enclose every HTML page. The `<html>` element must have two child elements within it. The `<head>` element contains metadata about the document, like the page title that is shown in the browser tab and the CSS style sheet that should be applied. The `<body>` element then contains all of the content that you see in the browser.

- Block elements are used to give structure to the page. These are elements like headings, sub-headings and so on from `<h1>` all the way down to `<h6>`. This category also contains paragraph elements `<p>`, ordered lists `<ol>` unordered lists `<ul>`. 

- Finally, inline tags like `<b>` for bold, `<i>` for italics, and `<a>` for hyperlinks are used to format text inside block elements.


When you come across a tag that you’ve never seen before, you can find out what it does with just a little bit of googling. A good resource here is the [MDN Web Docs](https://developer.mozilla.org/en-US/docs/Web/HTML) which are produced by Mozilla, the company that makes the Firefox web browser. The [W3schools website](https://www.w3schools.com/html/default.asp) is another great resource for web development and coding resources more generally.
:::

## HTML Attributes 

<br>

HTML attributes are contained within the opening tag. 

<br>

```{.html}
<tag attribute1='value1' attribute2='value2'>element contents</tag>
``` 

<br>

- `id` and `class` attributes are usually the most important in relation to web scraping.  

:::{.notes}
We've seen one example of a header with an additional attribute. More generally, all tags can have named attributes. These attributes are contained within the opening tag and look something like the code shown here.

Two of the most important attributes are `id` and `class`. These attributes are used in conjunction with the CSS file to control the visual appearance of the page. These are often very useful to identify the elements that you are interested in when scraping data off a page.
:::

## CSS Selectors 

- CSS has it's own system for selecting elements of a webpage: **selectors**. 

CSS Selectors can work on the level of an element type, a class, or a tag and these can be used in a nested (or _cascading_) way. 

. . . 

- The `p` selector will select all paragraph `<p>` elements.

- The `.title` selector will select all elements with class `“title”`.

- The `p.special` selector will select all`<p>` elements with class `“special”`.

- The `#title` selector will select the element with the id attribute `“title”`.  

:::{.notes}
The Cascading Style Sheet is used to describe how your HTML content will be displayed. To do this, CSS has it's own system for selecting elements of a webpage, called CSS selectors. 

CSS selectors define patterns for locating the HTML elements that a particular style should be applied to. A happy side-effect of this is that they can sometimes be very useful for scraping, because they provide a concise way of describing which elements you want to extract.

CSS Selectors can work on the level of an element type, a class, or a tag and these can be used in a nested (or _cascading_) way. 

(press for list to appear) 

- The `p` selector will select all paragraph `<p>` elements.

- The `.title` selector will select all elements with class `“title”`.

- The `p.special` selector will select all`<p>` elements with class `“special”`.

- The `#title` selector will select the element with the id attribute `“title”`. 

When you want to select a single element `id` attributes are particularly useful because that _must_ be unique within a html document. Unfortunately, this is only helpful if the developer added an `id` attribute to the element(s) you want to scrape! 

If you want to learn more CSS selectors I recommend starting with the fun [CSS dinner tutorial](https://flukeout.github.io/) to build a base of knowledge and then using the [W3schools resources](https://www.w3schools.com/css/default.asp) as a reference to explore more webpages in the wild. 
:::

## Which Attributes and Selectors Do You Need?

Before you can scrape data, you first need to be able to describe what you want to scrape! 

- right click + "inspect page source" (F12)
- right click + "inspect" 
- Rvest [Selector Gadget](https://rvest.tidyverse.org/articles/selectorgadget.html) (very useful but fallible) 

Start simple and build your confidence. Dynamic webpages can be more difficult. 

:::{.notes}
To scrape data from a webpage, you first have to identify the tag and attribute combinations that you are interested in gathering. 

To find your elements of interest, you have three options. These go from hardest to easiest but also from most to least robust. 

- right click + "inspect page source" (F12)
- right click + "inspect" 
- Rvest [Selector Gadget](https://rvest.tidyverse.org/articles/selectorgadget.html) (very useful but fallible)

Inspecting the source of some familiar websites can be a useful way to get your head around these concepts. Beware though that sophisticated webpages can be quite intimidating. A good place to start is with simpler, static websites such as personal websites, rather than the dynamic webpages of online retailers or social media platforms. 
:::

# 2. Reading HTML with `{rvest}`

<br>

```{r}
#| out-width: "240"
#| out-height: "278"
#| fig-align: center
knitr::include_graphics("images/rvest-logo.png")
```


## Reading HTML with `{rvest}`

<br>

`{rvest}` gives us funcitonality just like `{readr}`.

```{r}
#| echo: true 
#| eval: true
html <- rvest::read_html("https://www.zakvarty.com/professional/teaching.html")
class(html)
```

<br>

Rather than a `tibble` we get an `xml_document`, an object from `{xml2}`.

```{r}
#| echo: true 
#| eval: true
html
```

:::{.notes}
With `{rvest}`, reading a html page can be as simple as loading in tabular data. 

The `class` of the resulting object is an `xml_document`. This type of object is from the low-level package `{xml2}`, which allows you to read xml files into R.

We can see that this object is split into several components: first is some metadata on the type of document we have scraped, followed by the head and then the body of that html document. 

From here, we have several possible approaches to extracting information from this xml document. 
:::

## Extracting HTML elements

```{r}
#| echo: true
#| eval: true
#| collapse: true
library(rvest)
html %>% html_element("h1")
html %>% html_elements("h2")
html %>% html_elements("p") 
```

<br>

```{r}
#| echo: true
#| eval: true
html %>% html_elements("p a,h2")
```

::: {.notes}
n `{rvest}` you can extract a single element with `html_element()`, or all matching elements with `html_elements()`. Both functions take a document object and one or more CSS selectors as inputs.  

In the top code block are examples of extracting the first level-one header, all h2 level headers and then all paragraph elements of the webpage.

You can also combine and nest these selectors. For example you might want to extract all links that are within paragraphs *and* all second level headers. This is demonstrated in the second code block, where a space functions like an "and" connection between element types and a comma functions like an "or" connection.
:::


## Extracting data from HTML elements

<br>

- We have the HTML elements we care about... now what? 

<br>

- Depends if you are interested in the contents or the attributes of those elements. 

<br>

- Ideally, someone else will have put everything into a table for you already! 

::: {.notes}
Now that we’ve got the elements we care about extracted from the complete document. But how do we get the data we need out of those elements?

You’ll usually get the data from either the contents of the HTML element or else from one of it's attributes. If you're really lucky, the data you need will already be formatted for you as a HTML table or list.
:::


## Extracting text 

Extract text using `rvest::html_text()` or `rvest::html_text2()`.

<br>

```{r}
#| echo: true
#| eval: true
html %>% 
  html_elements("#teaching li") %>% 
  html_text2()
```

<br>
Do you want to extract like the HTML file or like the browser display?

::: {.notes}
The functions `rvest::html_text()` and `rvest::html_text2()` can be used to extract the plain text contents of an HTML element. 

The difference between `html_text()` and `html_text2()` is in how they handle whitespace. In HTML whitespace and line breaks have very little influence over how the code is interpreted by the computer (this is similar to R but very different from Python). `html_text()` will extract the text as it is in the raw html, while `html_text2()` will do its best to extract the text in a way that gives you something similar to what you’d see in the browser.
:::

## Extracting Attributes 

<br>

- Attributes can also contain useful data that you want to extract (links, image sizes, image paths,...).

- Get twitter link from the icon in the footer of the webpage using [Selector Gadget](https://rvest.tidyverse.org/articles/selectorgadget.html).

```{r}
#| echo: true 
#| eval: true
html %>% html_element(".compact:nth-child(1) .nav-link")
``` 

::: {.notes}
Attributes are also used to record information that you might like to collect. For example, the destination of links are stored in the `href` attribute and the source of images is stored in the `src` attribute.

As an example of this, consider trying to extract the twitter link from the icon in the page footer. This is quite tricky to locate in the html source, so I used the [Selector Gadget](https://rvest.tidyverse.org/articles/selectorgadget.html) to help find the correct combination of elements.
:::

## Extracting Attributes (2)

- Extract the `href` attribute.

<br>

```{r}
#| echo: true
#| eval: true
html %>% 
  html_elements(".compact:nth-child(1) .nav-link") %>% 
  html_attr("href")
```

<br>

*Note:* Attributes are always extracted as strings, so may need reformatting before analysis.

::: {.notes}
To extract the `href` attribute from the scraped element, we use the `rvest::html_attr()` function. 

One thing to note here is that `rvest::html_attr()` will always return a character string (or list of character strings). If you are extracting an attribute that describes a quantity, such as the width of an image, you'll need to convert this from a string to your required data type. For example, of the width is measures in pixels you might use `as.integer()`.
:::

## HTML Tables 

There are four main elements to know about that make up an HTML table: 

<br>

- `<table>`, 
- `<tr>` (table row),
- `<th>` (table heading),
- `<td>` (table data).  

::: {.notes}
Moving on now, let's consider the ideal case where the information you want is already nicely formatted into a table. HTML tables are composed in a similar, nested manner to LaTeX tables. 

There are four main elements to know about that make up an HTML table: 

- The `<table>` tag encloses the entire table environment

- One `<tr>` table row tag encloses each row of the table, including the header.

- The `<th>` table header tag encloses each entry in the header of the table,

- And finally the `<td>` table data tag encloses each entry in the body of the table. 
:::

## Example HTML Table {.smaller}

<br>

```{r}
html_2 <- minimal_html("
  <table>
    <tr>
      <th>Name</th>
      <th>Number</th>
    </tr>
    <tr>
      <td>A</td>
      <td>1</td>
    </tr>
    <tr>
      <td>B</td>
      <td>2</td>
    </tr>
    <tr>
      <td>C</td>
      <td>3</td>
    </tr>
  </table>
  ")
```

```{.html}
<table>
  <tr>
    <th>Name</th>
    <th>Number</th>
  </tr>
  <tr>
    <td>A</td>
    <td>1</td>
  </tr>
  <tr>
    <td>B</td>
    <td>2</td>
  </tr>
  <tr>
    <td>C</td>
    <td>3</td>
  </tr>
</table>
```

:::{.notes}
Here’s our simple example data, formatted as an HTML table. There is a Name column containing the letters A, B and C, then a Number column containing 1,2 and 3. 

We'll save this as a minimal html object called `html_2`. 
:::

## Extracting HTML Tables 

<br>

`{rvest}` has a useful function `html_table()` to help us. 

<br>
```{r}
#| echo: true
#| eval: true
html_2 %>% 
  html_element("table") %>% 
  html_table()
```

:::{.notes}
Since tables are a common way to store data, `{rvest}` includes a useful function `html_table()` that converts directly from an HTML table into a tibble.
:::


## Extracting HTML Tables (2) {.smaller}

<br>
<br>

```{r}
#| echo: true
#| eval: true
html %>% 
  html_element("table") %>% 
  html_table()
```

:::{.notes}
We can apply this same workflow to our scraped website data to easily extract the table on teaching activities. 

We first extract the HTML table using `html_element()` and then format it is a tibble using `html_table()`. 
:::

## Tip when building tibbles 

<br>

- Aim: build a tibble with 1 row per observation unit in the HTML (table row, list item, etc).

1. Use `html_elements()` to select the elements that contain each observation unit;

2. Use `html_element()` to extract the variables from each of those observations.

This avoids issues with missing values. 

:::{.notes}
When scraping data from a webpage, your end-goal is typically going to be constructing a data.frame or a tibble. 

If you are following our description of tidy data, you'll want each row to correspond some repeated unit on the HTML page. In this case, you should 

1. Use `html_elements()` to select the elements that contain each observation unit;
2. Use `html_element()` to extract the variables from each of those observations.

Taking this approach guarantees that you’ll get the same number of values for each variable, because `html_element()` always returns the same number of outputs as inputs. This is vital when you have missing data - when not every observation unit has a value for every variable of interest. 
:::
## Tip Example: Star Wars 

<br>

Example from the [star wars dataset](https://dplyr.tidyverse.org/reference/starwars.html#ref-examples).

<br>

```{r}
#| echo: true
#| eval: true
starwars_html <- minimal_html("
  <ul>
    <li><b>C-3PO</b> is a <i>droid</i> that weighs <span class='weight'>167 kg</span></li>
    <li><b>R2-D2</b> is a <i>droid</i> that weighs <span class='weight'>96 kg</span></li>
    <li><b>Yoda</b> weighs <span class='weight'>66 kg</span></li>
    <li><b>R4-P17</b> is a <i>droid</i></li>
  </ul>
  ")
```

::: {.notes}
As an example, consider this extract of text about the [starwars dataset](https://dplyr.tidyverse.org/reference/starwars.html#ref-examples).

This is an unordered list where each list item corresponds to one observational unit (one character from the starwars universe). The name of the character is given in bold, the character species is specified in italics and the weight of the character is denoted by the `.weight` class. However, some characters have only a subset of these variables defined: for example Yoda has no species entry.  
:::

## Tip Example: what not to do 

<br>

Do not try to extract each element directly: vectors of differing lengths.

<br>

```{r}
#| echo: true
#| eval: true
starwars_html %>% html_elements("b") %>% html_text2()
starwars_html %>% html_elements("i") %>% html_text2()
starwars_html %>% html_elements(".weight") %>% html_text2()
```

:::{.notes}
If we try to extract each element directly, our vectors of variable values are of different lengths. Since we don't know where the missing values should be within these vectors, so we can't add them back in and  make a tibble from this data. 
:::


## Tip Example: correct approach 

First select the elements that contain each observation unit.

```{r}
#| echo: true
#| eval: true
#| collapse: true
starwars_characters <- starwars_html %>% html_elements("li")
```

Then extract the variables from each of those observations.

```{r}
#| echo: true
#| eval: true
tibble::tibble(
  name = starwars_characters %>% html_element("b") %>% html_text2(),
  species = starwars_characters %>% html_element("i") %>% html_text2(),
  weight = starwars_characters %>% html_element(".weight") %>% html_text2()
)
``` 

:::{.notes}
What we should do instead is start by extracting all of the list item elements using `html_elements()`. Once we have done this, we can then use `html_element()` to extract each variable for all characters. This will pad with NAs, so that we can collate them into a tibble. 
::: 

## Wrapping Up 

<br>

1. Structure of webpages. 

<br>

2. Using `{rvest}` package to extract the elements of interest.

<br>

3. Formatting those extracted into useful formats. 

:::{.notes}
With that, let's wrap up this video. 

We've learned about the way that webpages are structured, and how this structure can help us locate parts of the webpage that we would like to extract. 

We then covered how functions from the `{rvest}` package can be used to easily extract this information. 

Finally we considered how to convert these extracted HTML elements into R objects that are amenable to further analysis. 

In this video we've covered all you need to get started scraping your own data from the internet. 

Thank you very much for your attention and I'll see you in the next video.
:::
